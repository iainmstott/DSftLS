
<!-- spiel -->
## 2 - DATA DISTRIBUTIONS


_The first section of this Chapter will be completed at home before this week's online workshop._
This first section contains _Quizzes_ and _Exercises_. These multi-
choice questions and `R` coding exercises will test your learning on this chapter's
topic.

_The second section of this worksheet will be completed during the online workshop in your tutor groups._
This section contains some tasks for you to complete with a real data set, on the 
topic of this Chapter. You'll be coding this yourselves in `R` using RStudio.  
\

Contine to Resources...


$~$

***
### RESOURCES

Books:
 
<-! ### *** Pages etc. -->
* [_R for Data Science_](https://r4ds.had.co.nz/) by Garrett Grolemund and Hadley Wickham. 
* [_Getting Started with R: An Introduction for Biologists (2nd ed)_](http://r4all.org/books/gswr2/) 
by Andrew Beckerman, Dylan Childs, and Owen Petchey, pp 87 - 91, Chapter 4.4, "Distributions:
making histograms of numeric variables", & Chapter 4.5, "Saving your graphs for 
presenatation, documentation, etc.".
\ 

Cheatsheets:

* ggplot2 cheatsheet - see Resources section on blackboard or 
download [here](https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf)
\ 

Web links:

* [ggglot2](https://ggplot2.tidyverse.org/) by RStudio  
\ 

* [_ShinyGLM_](https://iainmstott.shinyapps.io/ShinyGLiM)
\


##### **ShinyGLM**

We'll be using the [ShinyGLM](https://iainmstott.shinyapps.io/ShinyGLiM) webapp 
in this and subsequent chapters. It's designed to make learning data skills in `R`
an interactive experience. It's worth getting to know how to use it, so make sure 
to read the **USER GUIDE** now.  

In this Chapter, we'll mainly be working with the _DATA DISTRIBUTIONS_ tab.  
\


##### **R PACKAGES**  

We encountered **R packages** in the last 2 Chapters. In this Chapter we will 
need to use an R package developed by the RStudio team.

 * `ggplot2`, is an `R` package which makes pretty pretty data visualisations.

The package first needs to be installed onto your computer. Unless you 
update `R`, this only needs to be done _once_. 

```{r eval = FALSE}
install.packages("ggplot")
 ```
\

Once a package is installed, it is available for `R` to use. But unless you tell 
`R` to actually _use_ the package then it won't know it needs to. The reason for this
is that once you're using `R` a lot and have loads of packages installed, 
if you loaded _all_ the packages in every time you start `R` it would take forever.  

Think of it like apps on your phone: imagine if every single app on your phone opened 
every time you switched the phone on on, in case you needed to use it!  _Nightmare_.  

The way we load up these packages is using `library()`. Each package is loaded separately.

 ```{r eval = FALSE}
library(ggplot2)
 ```
\

```{r C02_packagesQ1, echo = FALSE}
quiz(caption = "Packages",
    question("What is library()?",
        answer("A function", correct = TRUE),
        answer("An object"),
        answer("An argument"),
        answer("A-nnoying"),

        random_answer_order = TRUE
    ),

    question("What is ggplot2?",
        answer("None of these", correct = TRUE, message = "Correct. In fact, loading packages means loading functions, objects and more into the R session."),
        answer("A character object"),
        answer("A logical object"),
        answer("An object"),
        answer("A function"),
        incorrect = "They are none of these. In fact, loading packages means loading functions, objects and more into the R session.",
        random_answer_order = TRUE
    )
)
```


***
### DATA DISTRIBUTIONS 
It's really important to understand the nature of your data. There are different 
types of data, and here are some of the types we regularly encounter as biologists:

* numeric
   + continuous: Gaussian, beta, exponential
   + discrete (counts): Poisson, binomial
* non-numeric
   + categorical
   + ordinal
\

Let's remind ourselves of the different distributions found in the _**games**_ 
data. 

```{r C02_distributionsQ1, echo = FALSE}
quiz(caption = "Data distributions",
    question("What distribution does the paper balls variable follow?",
        answer("poisson", correct = TRUE),
        answer("Gaussian"),
        answer("binomial"),
        answer("categorical"),
        incorrect = "It's a poisson variable as it's a count.",
        random_answer_order = TRUE
    ),

    question("What distribution does the reaction time follow?",
        answer("beta", correct = TRUE),
        answer("ordinal"),
        answer("poisson"),
        answer("categorical"),
        incorrect = "It's beta, which is the distribution that describes proportions.",
        random_answer_order = TRUE
    ),

    question("Is Tutor Group categorical or ordinal?",
        answer("categorical", correct = TRUE),
        answer("ordinal"),
        incorrect = "It's categorical, as it has no natural hierarchy (even if you do think 
        your tutor group is the best in the year group...).",
        random_answer_order = TRUE
    ),

        question("What distribution does the glasses prescription follow?",
        answer("Gaussian", correct = TRUE),
        answer("poisson"),
        answer("beta"),
        answer("ordinal"),
        incorrect = "It's Gaussian, as it can in theory take any continuous value.",
        random_answer_order = TRUE
    )
)
```
\

#### Data Distributions explained
\

Here's a little from me on adta distributions:  
\

<center>
![](https://youtu.be/d7lARa168gk){width="80%"}
</center>  
\  

The **distributions** of variables are important factors in how we 
interpret plots and analyses. Distributions are effectively 'counts' of the
number of times certain variable values occur (e.g. for the paper balls game 
the counts of occurrence of 0, 1, 2, 3, 4,...), or the number of times variable 
values occur within certain intervals (e.g. for the forward fold the number of 
values between -3 to -2, -2 to -1, -1 to 0,...).  

Distributions also show us how variables are 
_bounded_ (i.e. cannot occur above, below or between certain values), 
how they are _skewed_ (e.g. there are lots of small values but not many large ones),
which _statistical distributions_ the data approximate, and what that means 
for their _moments_ (mean, variance, skewness). All of these things can have implications
for how you analyse your data, and how you interpret your results.

<!--
In this particular session, we're going to acquaint ourselves with the 
[`ggplot2`](https://ggplot2.tidyverse.org/) package. `ggplot2` is a great 
package for data visualisation: it's easy to make very pretty graphs with 
only a few lines of code, and has simplified many data visualisation problems 
which previously were tricky in R. We'll be learning:

* a reinforcement of data-handling skills
* an understanding of the grammar of graphics and how ggplot uses it
* how plot histograms
   + `ggplot()` and `aes()` to initialise a plot
   + adjustments to coordinates
   + `geom_histogram` to map a histogram 
   + how to change the look of a plot with themes and other options  
\
-->

### VISUALISING DATA DISTRIBUTIONS
 \

Data distributions are most commonly visualised using a **histogram**.  
\

##### **EYESIGHT**  
\  

We're going to begin by working with the forward fold (`ffold`) variable. For now,
we'll keep all of the data points, so don't make any changes to the data frame.  

Head on over to the DATA VISUALISATION (ONE VARIABLE) page. Choose to plot the 
forward fold (`ffold`) variable. Keep all of the other options at their defaults, for now.  

_Question: how would you describe the distribution of the forward fold variable?
Think about what the characteristics of a distribution are, and what characteristics
this distribution has. Think about what characteristics you would expect the 
distribution to have. Do your expectations match the reality?_  
\

Now try adjusting the number of bins that you're plotting. Try higher numbers, and try lower.
As you adjust the number of bins, look at the CODE tab to see what changes.  

_Questions:_

* _What happens if you increase the number of bins?_
* _What happens if you descrease the number of bins?_
* _What do you think is the perfect bin number to use?_
\

Now getting back CODE tab, look at how the code changes as you change the number of bins.  

_Question: when changing the number of bins, which of the following changes in
the code?_

* a __function__
* an __argument__ 
* an __object__ 
* an __option__
\

You can probably guess by looking at the code how elements of the code match up to the rest of the options in the app. 
As I have said all along so far, R is very literal! Have a guess at what 
will change in the code if you change the x axis limits, the fill colour for 
the bars, and the theme.  

_Questions:_ 

*_Did the code change in the way you expected, and if not, how was it different?  _
* _What's the best colour to plot the bars with?  _
* _What's the nicest theme, and are there any other themes than the ones listed? 
(Hint: Google is your friend when it comes to finding out new things about R)._  
\

Cast your mind back to the _BGY2010M W1.2 Data handling_ worksheet, because 
you're going to have to remember something you learned! You want to look 
at the 'games' data for only people who can't touch the floor, as you have a theory 
that their tight muscle tension could mean they have quicker reactions 
(the `ruler` variable).  

_Task: work out (without looking at the app!) which of these three pieces of code 
give the correct way to subset the data in the way described above._

```{r eval=FALSE}
# a)
data %>% filter(ffold %over% 0)

# b)
data %>% slice(ffold >= 0)

# c)
data %>% select(ffold > 0)

# d)
data %>% filter(ffold > 0)

```
\

Now, head to the DATA page and subset the data to only people who can't touch the 
floor. See whether you got the above answer right.  
\

Returning to the DATA VISUALISATION (ONE VARIABLE) page, see how subsetting 
the data has changed your plot.  

_Question: think back to the start of this worksheet and what you thought about
the characteristics of the distribution of the `ffold` variable. Now that you've subsetted the `ffold` data, have those thoughts changed?_  
\



#### RULER REACTION

Now plot a histogram of the `ruler` variable, still just for people who can't 
touch the floor.  

_Question: what x-axis limits should you probably choose?_  
\

Choose what number bins you think works best, and add a
density plot on top. Take a mental (or literal) snapshot of what the plot looks 
like. Head back to the DATA page, undo your subset to revert back to the full data set, then see how the plot has changed on the DATA VISUALISATION (ONE VARIABLE) page.  

_Question: Are the two distributions similar, or different? What might that tell
us about the hypothesis?_  
\


#### PAPER BALLS

Now, with the whole data set, we'll plot the distribution of the paper balls 
variable. Choose a number of histogram bins that you're comfortable with, and then add a density plot.  

_Task: Without looking at the CODE tab, find the mistake(s) in the code below 
and correct them to give you the code needed to produce the plot._

```{r eval= FALSE}
hist <- ggplot(data, x = pballs)
    geom_histogram(aes(y = ..density..), bins: 8, fill: steelblue4) + 
    # your bin numbers and colour may be different to above!
    xlim(c(0, 10))
    # your xlim may be different to above!
    theme("minimal")
    # your theme may be different to above!

hist + geom_density(color = 'white', bars = 'darkgrey', alpha = 0.5)
```
\

Check the code tab to see whether you managed to catch the mistakes properly.  

_Question: what do you think the `alpha` value does in the `geom_density()`
function?_  
\

Finally, you may notice that in the _Getting started with R_ book, they don't
use `y = ..density..` when plotting histograms. This is included here so that
it's possible to see the density plot on top. For a probability density histogram,
each bar represents the proportion of the data that takes a certain range of
values. If we use a histogram of counts, it's the number of data points that
have a certain value.  

_Task: a count histogram is probably more relevant for the `pballs` variable. 
How would we change the code to get counts? (Hint: take a look in the 
Getting Started with R book)._  
\



***
***

### DATA VISUALISATION (ONE VARIABLE): PART 2

In this part, we'll start looking at real data sets. There are several
to choose from, each with a suggested hypothesis, and you can find them in the 
DataDescription.html file in the DATA section on Blackboard.  
\

_Tasks: For your chosen data and hypothesis, you need to:_

* _Subset the data by removing any rows (and perhaps columns) which are not
needed._
* _Add to the data frame any extra variables you need for your analysis (if any)._
* _Plot the distributions of the numeric variables you'll include in your
analysis. At this point, response variables should be variables with Gaussian (normal) distributions (talk to me if you need any clarification on this)._
* _Draw some conclusions about the distributions of your variables..._
   + _Are the variables continuous (can take any number) or discrete (usually counts)?_
   + _Are they bounded at all?_
   + _Are they skewed, and how does that compare to what you would expect?_
   + _What are their __moments__ (mean, variance, median, mode, skewness) likely to be?_  
\

On this last point: moments of data are easy to calculate. You can use, e.g.
```{r eval = FALSE}
mean(data$pballs) # if there are missing values add na.rm = TRUE
median(data$pballs) 

# calculating other moments requires using a package
install.packages("moments")
skewness(data$pballs)
```
\  
\  



